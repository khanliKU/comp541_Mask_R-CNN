{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "using Knet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dummy"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc randn\n",
    "dummy = KnetArray(Float32.(randn((512,512,3,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "struct Conv; w; b; f; p; end\n",
    "(c::Conv)(x) = c.f.(pool(conv4(c.w, dropout(x,c.p)) .+ c.b))\n",
    "Conv(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicStem"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a convolutional layer:\n",
    "struct BasicStem; w; b; f; p; end\n",
    "(bs::BasicStem)(x) = bs.f.(pool(conv4(bs.w, dropout(x,bs.p),stride=2,padding=3) .+ bs.b,window=2))\n",
    "BasicStem(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = BasicStem(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "conv4(w, x; kwargs...)\n",
       "\\end{verbatim}\n",
       "Execute convolutions or cross-correlations using filters specified with \\texttt{w} over tensor \\texttt{x}.\n",
       "\n",
       "If \\texttt{w} has dimensions \\texttt{(W1,W2,...,Cx,Cy)} and \\texttt{x} has dimensions \\texttt{(X1,X2,...,Cx,N)}, the result \\texttt{y} will have dimensions \\texttt{(Y1,Y2,...,Cy,N)} where \\texttt{Cx} is the number of input channels, \\texttt{Cy} is the number of output channels, \\texttt{N} is the number of instances, and \\texttt{Wi,Xi,Yi} are spatial dimensions with \\texttt{Yi} determined by:\n",
       "\n",
       "\\begin{verbatim}\n",
       "Yi = 1 + floor((Xi + 2*padding[i] - ((Wi-1)*dilation[i] + 1)) / stride[i])\n",
       "\\end{verbatim}\n",
       "\\texttt{padding}, \\texttt{stride} and \\texttt{dilation} are keyword arguments that can be specified as a single number (in which case they apply to all dimensions), or an array/tuple with entries for each spatial dimension.\n",
       "\n",
       "\\section{Keywords}\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{padding=0}: the number of extra zeros implicitly concatenated at the start and end of each dimension.\n",
       "\n",
       "\n",
       "\\item \\texttt{stride=1}: the number of elements to slide to reach the next filtering window.\n",
       "\n",
       "\n",
       "\\item \\texttt{dilation=1}: dilation factor for each dimension.\n",
       "\n",
       "\n",
       "\\item \\texttt{mode=0}: 0 for convolution and 1 for cross-correlation (which flips the filter).\n",
       "\n",
       "\n",
       "\\item \\texttt{alpha=1}: can be used to scale the result.\n",
       "\n",
       "\n",
       "\\item \\texttt{group=1}: can be used to perform grouped convolutions.\n",
       "\n",
       "\\end{itemize}\n"
      ],
      "text/markdown": [
       "```\n",
       "conv4(w, x; kwargs...)\n",
       "```\n",
       "\n",
       "Execute convolutions or cross-correlations using filters specified with `w` over tensor `x`.\n",
       "\n",
       "If `w` has dimensions `(W1,W2,...,Cx,Cy)` and `x` has dimensions `(X1,X2,...,Cx,N)`, the result `y` will have dimensions `(Y1,Y2,...,Cy,N)` where `Cx` is the number of input channels, `Cy` is the number of output channels, `N` is the number of instances, and `Wi,Xi,Yi` are spatial dimensions with `Yi` determined by:\n",
       "\n",
       "```\n",
       "Yi = 1 + floor((Xi + 2*padding[i] - ((Wi-1)*dilation[i] + 1)) / stride[i])\n",
       "```\n",
       "\n",
       "`padding`, `stride` and `dilation` are keyword arguments that can be specified as a single number (in which case they apply to all dimensions), or an array/tuple with entries for each spatial dimension.\n",
       "\n",
       "# Keywords\n",
       "\n",
       "  * `padding=0`: the number of extra zeros implicitly concatenated at the start and end of each dimension.\n",
       "  * `stride=1`: the number of elements to slide to reach the next filtering window.\n",
       "  * `dilation=1`: dilation factor for each dimension.\n",
       "  * `mode=0`: 0 for convolution and 1 for cross-correlation (which flips the filter).\n",
       "  * `alpha=1`: can be used to scale the result.\n",
       "  * `group=1`: can be used to perform grouped convolutions.\n"
      ],
      "text/plain": [
       "\u001b[36m  conv4(w, x; kwargs...)\u001b[39m\n",
       "\n",
       "  Execute convolutions or cross-correlations using filters specified with \u001b[36mw\u001b[39m\n",
       "  over tensor \u001b[36mx\u001b[39m.\n",
       "\n",
       "  If \u001b[36mw\u001b[39m has dimensions \u001b[36m(W1,W2,...,Cx,Cy)\u001b[39m and \u001b[36mx\u001b[39m has dimensions \u001b[36m(X1,X2,...,Cx,N)\u001b[39m,\n",
       "  the result \u001b[36my\u001b[39m will have dimensions \u001b[36m(Y1,Y2,...,Cy,N)\u001b[39m where \u001b[36mCx\u001b[39m is the number of\n",
       "  input channels, \u001b[36mCy\u001b[39m is the number of output channels, \u001b[36mN\u001b[39m is the number of\n",
       "  instances, and \u001b[36mWi,Xi,Yi\u001b[39m are spatial dimensions with \u001b[36mYi\u001b[39m determined by:\n",
       "\n",
       "\u001b[36m  Yi = 1 + floor((Xi + 2*padding[i] - ((Wi-1)*dilation[i] + 1)) / stride[i])\u001b[39m\n",
       "\n",
       "  \u001b[36mpadding\u001b[39m, \u001b[36mstride\u001b[39m and \u001b[36mdilation\u001b[39m are keyword arguments that can be specified as\n",
       "  a single number (in which case they apply to all dimensions), or an\n",
       "  array/tuple with entries for each spatial dimension.\n",
       "\n",
       "\u001b[1m  Keywords\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "    •    \u001b[36mpadding=0\u001b[39m: the number of extra zeros implicitly concatenated at\n",
       "        the start and end of each dimension.\n",
       "\n",
       "    •    \u001b[36mstride=1\u001b[39m: the number of elements to slide to reach the next\n",
       "        filtering window.\n",
       "\n",
       "    •    \u001b[36mdilation=1\u001b[39m: dilation factor for each dimension.\n",
       "\n",
       "    •    \u001b[36mmode=0\u001b[39m: 0 for convolution and 1 for cross-correlation (which flips\n",
       "        the filter).\n",
       "\n",
       "    •    \u001b[36malpha=1\u001b[39m: can be used to scale the result.\n",
       "\n",
       "    •    \u001b[36mgroup=1\u001b[39m: can be used to perform grouped convolutions."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BottleneckBlock_b"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a convolutional layer:\n",
    "struct BottleneckBlock_b; w0; w1; w2; w3; p; end\n",
    "(this::BottleneckBlock_b)(x) = relu.(\n",
    "    conv4(this.w3, dropout(\n",
    "            relu.(conv4(this.w2, dropout(\n",
    "                    relu.(conv4(this.w1, dropout(x,this.p)))\n",
    "                    ,this.p),\n",
    "                    padding=1)\n",
    "                )\n",
    "            ,this.p)) .+\n",
    "    conv4(this.w0, dropout(x,this.p))\n",
    ")\n",
    "BottleneckBlock_b(cx::Int,cy::Int;pdrop=0) =\n",
    "    BottleneckBlock_b(\n",
    "        param(1,1,cx,cy), #w0\n",
    "        param(1,1,cx,cx), #w1\n",
    "        param(3,3,cx,cx), #w2\n",
    "        param(1,1,cx,cy), #w3\n",
    "        pdrop\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "pool(x; kwargs...)\n",
       "\\end{verbatim}\n",
       "Compute pooling of input values (i.e., the maximum or average of several adjacent values) to produce an output with smaller height and/or width.\n",
       "\n",
       "If \\texttt{x} has dimensions \\texttt{(X1,X2,...,Cx,N)}, the result \\texttt{y} will have dimensions \\texttt{(Y1,Y2,...,Cx,N)} where\n",
       "\n",
       "\\begin{verbatim}\n",
       "Yi=1+floor((Xi+2*padding[i]-window[i])/stride[i])\n",
       "\\end{verbatim}\n",
       "Here \\texttt{Cx} is the number of input channels, \\texttt{N} is the number of instances, and \\texttt{Xi,Yi} are spatial dimensions.  \\texttt{window}, \\texttt{padding} and \\texttt{stride} are keyword arguments that can be specified as a single number (in which case they apply to all dimensions), or an array/tuple with entries for each spatial dimension.\n",
       "\n",
       "\\section{Keywords:}\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{window=2}: the pooling window size for each dimension.\n",
       "\n",
       "\n",
       "\\item \\texttt{padding=0}: the number of extra zeros implicitly concatenated at the start and at the end of each dimension.\n",
       "\n",
       "\n",
       "\\item \\texttt{stride=window}: the number of elements to slide to reach the next pooling window.\n",
       "\n",
       "\n",
       "\\item \\texttt{mode=0}: 0 for max, 1 for average including padded values, 2 for average excluding padded values, 3 for deterministic max.\n",
       "\n",
       "\n",
       "\\item \\texttt{maxpoolingNanOpt=1}: Nan numbers are not propagated if 0, they are propagated if 1.\n",
       "\n",
       "\n",
       "\\item \\texttt{alpha=1}: can be used to scale the result.\n",
       "\n",
       "\\end{itemize}\n"
      ],
      "text/markdown": [
       "```\n",
       "pool(x; kwargs...)\n",
       "```\n",
       "\n",
       "Compute pooling of input values (i.e., the maximum or average of several adjacent values) to produce an output with smaller height and/or width.\n",
       "\n",
       "If `x` has dimensions `(X1,X2,...,Cx,N)`, the result `y` will have dimensions `(Y1,Y2,...,Cx,N)` where\n",
       "\n",
       "```\n",
       "Yi=1+floor((Xi+2*padding[i]-window[i])/stride[i])\n",
       "```\n",
       "\n",
       "Here `Cx` is the number of input channels, `N` is the number of instances, and `Xi,Yi` are spatial dimensions.  `window`, `padding` and `stride` are keyword arguments that can be specified as a single number (in which case they apply to all dimensions), or an array/tuple with entries for each spatial dimension.\n",
       "\n",
       "# Keywords:\n",
       "\n",
       "  * `window=2`: the pooling window size for each dimension.\n",
       "  * `padding=0`: the number of extra zeros implicitly concatenated at the start and at the end of each dimension.\n",
       "  * `stride=window`: the number of elements to slide to reach the next pooling window.\n",
       "  * `mode=0`: 0 for max, 1 for average including padded values, 2 for average excluding padded values, 3 for deterministic max.\n",
       "  * `maxpoolingNanOpt=1`: Nan numbers are not propagated if 0, they are propagated if 1.\n",
       "  * `alpha=1`: can be used to scale the result.\n"
      ],
      "text/plain": [
       "\u001b[36m  pool(x; kwargs...)\u001b[39m\n",
       "\n",
       "  Compute pooling of input values (i.e., the maximum or average of several\n",
       "  adjacent values) to produce an output with smaller height and/or width.\n",
       "\n",
       "  If \u001b[36mx\u001b[39m has dimensions \u001b[36m(X1,X2,...,Cx,N)\u001b[39m, the result \u001b[36my\u001b[39m will have dimensions\n",
       "  \u001b[36m(Y1,Y2,...,Cx,N)\u001b[39m where\n",
       "\n",
       "\u001b[36m  Yi=1+floor((Xi+2*padding[i]-window[i])/stride[i])\u001b[39m\n",
       "\n",
       "  Here \u001b[36mCx\u001b[39m is the number of input channels, \u001b[36mN\u001b[39m is the number of instances, and\n",
       "  \u001b[36mXi,Yi\u001b[39m are spatial dimensions. \u001b[36mwindow\u001b[39m, \u001b[36mpadding\u001b[39m and \u001b[36mstride\u001b[39m are keyword\n",
       "  arguments that can be specified as a single number (in which case they apply\n",
       "  to all dimensions), or an array/tuple with entries for each spatial\n",
       "  dimension.\n",
       "\n",
       "\u001b[1m  Keywords:\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "    •    \u001b[36mwindow=2\u001b[39m: the pooling window size for each dimension.\n",
       "\n",
       "    •    \u001b[36mpadding=0\u001b[39m: the number of extra zeros implicitly concatenated at\n",
       "        the start and at the end of each dimension.\n",
       "\n",
       "    •    \u001b[36mstride=window\u001b[39m: the number of elements to slide to reach the next\n",
       "        pooling window.\n",
       "\n",
       "    •    \u001b[36mmode=0\u001b[39m: 0 for max, 1 for average including padded values, 2 for\n",
       "        average excluding padded values, 3 for deterministic max.\n",
       "\n",
       "    •    \u001b[36mmaxpoolingNanOpt=1\u001b[39m: Nan numbers are not propagated if 0, they are\n",
       "        propagated if 1.\n",
       "\n",
       "    •    \u001b[36malpha=1\u001b[39m: can be used to scale the result."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BottleneckBlock_b(P(KnetArray{Float32,4}(1,1,3,3)), P(KnetArray{Float32,4}(1,1,3,3)), P(KnetArray{Float32,4}(3,3,3,3)), P(KnetArray{Float32,4}(1,1,3,3)), 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummybb_b = BottleneckBlock_b(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.445986 seconds (18.23 M allocations: 923.061 MiB, 6.87% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512×512×3×1 KnetArray{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       " 1.86114   0.0       0.542849  1.62628     …  0.955678   0.965414   0.972152\n",
       " 0.0       0.0       2.5603    0.0            0.0        2.89676    0.954212\n",
       " 0.0       0.0       0.0       0.0            0.786457   0.969218   0.301087\n",
       " 0.0       0.0       0.760335  0.0            0.41926    0.0        0.267461\n",
       " 0.0       0.0       0.0       1.58539        0.0        2.25346    0.504671\n",
       " 0.0       0.0       0.0       0.0         …  0.0        0.0        0.0\n",
       " 1.1129    0.0       0.0       0.369513       0.0        1.41014    0.0\n",
       " 0.0       0.0       1.82711   0.0            0.0        0.982605   0.148999\n",
       " 0.37624   0.604688  0.745195  0.0348488      0.506591   0.0        0.564787\n",
       " 1.43722   1.60575   0.0       0.432641       0.0        2.05851    0.127971\n",
       " 1.62786   0.0       0.448428  2.50721     …  0.0        0.0299819  0.641027\n",
       " 0.0       0.0       0.0       0.0            0.0        0.388475   0.0\n",
       " 0.0       1.09188   0.0       0.0            0.0        0.0        0.0\n",
       " ⋮                                         ⋱             ⋮          \n",
       " 0.901658  0.0       0.0       1.59819     …  0.0        2.3473     0.0\n",
       " 0.0       0.0       1.48085   0.0            0.0        0.349423   0.0\n",
       " 0.0       2.31939   0.790948  0.0            0.0850563  0.0        1.40075\n",
       " 2.34492   0.411157  0.0       0.0            2.19787    0.0        0.209307\n",
       " 0.0       0.0       1.51361   0.25045        1.11228    0.0        0.0\n",
       " 0.0       0.276212  0.574522  0.0400791   …  0.0        0.0        1.02691\n",
       " 0.820007  2.5743    0.485934  0.0            0.0        1.26312    0.0\n",
       " 0.403278  0.0       0.846309  0.0            0.789152   0.0        0.0\n",
       " 0.0       0.0       0.0       0.00631613     0.0        0.0        0.0\n",
       " 0.0       0.0       2.24337   0.0            0.0        0.0        0.0\n",
       " 0.62745   0.0       0.440401  0.80916     …  0.0        0.164717   0.0\n",
       " 0.109547  4.09926   0.342177  0.252742       1.12777    0.0        0.0\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.0       0.0       0.283911   0.0        …  0.0        0.0       0.0\n",
       " 0.841857  0.0       0.210367   0.0           2.3477     0.590054  0.358695\n",
       " 2.72574   0.0       3.05124    1.19549       0.0        0.0       2.66924\n",
       " 0.421553  1.91294   0.657421   0.242501      0.0        2.36672   0.0\n",
       " 1.12235   0.0       0.573698   0.0           0.858257   0.0       0.0\n",
       " 0.0       1.38686   0.0        3.0772     …  0.300436   1.62075   0.0\n",
       " 0.0       0.0       0.508681   0.0           0.823566   0.0       0.0\n",
       " 0.0       0.0       0.268296   0.0           0.611089   0.0       1.32472\n",
       " 3.21755   0.0       0.806239   1.92367       0.0        3.54244   0.0\n",
       " 0.0       0.0       0.0        1.34069       0.592933   2.31992   1.10868\n",
       " 1.16982   0.0       0.0        0.384635   …  0.0        0.0       0.0\n",
       " 0.0       2.99251   0.0        1.09745       0.0        0.722707  1.89471\n",
       " 2.8661    0.138386  0.0        0.67042       0.0        0.29789   0.0\n",
       " ⋮                                         ⋱             ⋮         \n",
       " 0.0       2.57923   1.16712    0.0500479  …  0.356791   0.0       0.0\n",
       " 0.0       0.848723  0.0        0.0           0.0479855  0.0       1.42578\n",
       " 0.0       0.0       0.0        0.0           0.0        0.0       3.61626\n",
       " 0.0       0.0       0.240741   0.0           0.0        0.0       0.0\n",
       " 1.40213   0.0       0.712236   0.647066      0.0        0.0       1.16733\n",
       " 0.0       3.14851   0.0        2.391      …  0.0        0.0       0.0\n",
       " 0.0       0.0       0.0        0.0           0.0        1.43864   1.70758\n",
       " 0.0       0.0       0.0        2.46431       0.0        0.0       0.0\n",
       " 2.10619   3.40554   0.0274473  0.0           0.0        2.81975   1.65746\n",
       " 0.0       0.0       0.0        0.0           0.0        2.93171   0.0\n",
       " 0.187095  0.0       1.99791    0.0        …  0.0        0.0       0.0\n",
       " 2.42426   2.97846   0.0        0.0232941     2.3483     0.0       0.0\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 2.43534   0.0       0.619012   0.736201   …  1.5737    2.35282     1.75585\n",
       " 1.28257   0.461104  2.25269    0.523099      0.301249  3.07623     2.22151\n",
       " 0.0       2.00522   0.649036   0.205399      1.30735   1.20541     1.09433\n",
       " 0.0       0.0       2.01742    0.195057      2.1599    0.0         0.0\n",
       " 0.294651  0.0       0.0        1.15782       0.557152  5.6911      0.0\n",
       " 0.0       0.0       0.0        0.0        …  0.0       0.0         3.11811\n",
       " 2.07401   0.734208  0.455451   0.0           1.40659   0.316791    0.223867\n",
       " 2.61107   0.0337    1.75103    0.0           0.6411    1.52494     0.0\n",
       " 0.0       1.50217   0.237326   0.973153      1.01051   0.0         0.853939\n",
       " 1.62612   0.608889  1.4972     0.0           1.42132   0.467498    0.398575\n",
       " 2.53091   0.642861  0.0277413  0.8825     …  1.24245   2.11078     0.0\n",
       " 1.37889   0.0       0.0716156  0.0           0.0       0.0         0.571855\n",
       " 0.0       0.0       0.0        1.62856       0.395548  0.233028    0.0\n",
       " ⋮                                         ⋱            ⋮           \n",
       " 0.0       0.0       0.521021   2.05495    …  0.0       1.71899     1.87079\n",
       " 0.979907  0.0       0.588508   1.09424       2.7569    0.49865     1.28442\n",
       " 1.13352   2.4166    1.20703    0.0           0.356746  2.25617     0.0\n",
       " 4.21301   2.69529   0.02123    0.819231      2.37778   0.0         3.05\n",
       " 2.60921   2.04821   0.0        0.0572387     0.0       2.95278     1.26922\n",
       " 0.0       0.0       0.606505   0.0        …  0.0       0.0         4.17578\n",
       " 0.0       2.89848   0.297708   0.0           0.0       1.38124     0.0\n",
       " 1.36383   1.2214    3.2157     0.0           0.199514  2.06607     0.0\n",
       " 0.0       1.4759    0.0        1.93564       2.19831   0.0         0.989432\n",
       " 0.0       1.92177   5.05386    0.0           0.440627  0.0         0.860861\n",
       " 0.0       1.27286   0.0        3.78071    …  0.0       0.240247    0.249655\n",
       " 0.0       0.934711  2.78094    0.0           1.07024   0.00282051  0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time dummybb_b(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BottleneckBlock_a"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a convolutional layer:\n",
    "struct BottleneckBlock_a; w1; w2; w3; p; end\n",
    "(this::BottleneckBlock_a)(x) = relu.(\n",
    "    conv4(this.w3, dropout(\n",
    "            relu.(conv4(this.w2, dropout(\n",
    "                    relu.(conv4(this.w1, dropout(x,this.p)))\n",
    "                    ,this.p),\n",
    "                    padding=1))\n",
    "            ,this.p)) .+\n",
    "    x\n",
    ")\n",
    "BottleneckBlock_a(cx::Int,cy::Int;pdrop=0) =\n",
    "    BottleneckBlock_a(\n",
    "        param(1,1,cx,cy), #w1\n",
    "        param(3,3,cy,cy), #w2\n",
    "        param(1,1,cy,cx), #w3\n",
    "        pdrop\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,3,1)), P(KnetArray{Float32,4}(3,3,1,1)), P(KnetArray{Float32,4}(1,1,1,3)), 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummybb_a = BottleneckBlock_a(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.027866 seconds (7.93 k allocations: 435.831 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512×512×3×1 KnetArray{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.0       0.508761  0.0        0.638269  …  0.0        0.0       0.0\n",
       " 0.0       0.0       0.464915   0.0          0.0        1.08543   0.445862\n",
       " 1.40298   0.0       0.63193    0.208365     0.0        0.359107  1.12401\n",
       " 0.0       1.09607   0.185778   0.212255     0.0        1.38321   0.9353\n",
       " 0.255622  0.0       0.155535   0.463058     0.0        0.0       1.40997\n",
       " 0.0       0.678276  0.0551335  1.05908   …  2.2331     0.846802  0.0\n",
       " 0.0       0.0       0.0        0.182355     0.0        0.699376  0.0276002\n",
       " 0.0       0.0       0.23589    0.0          0.0        0.0       1.25623\n",
       " 1.20527   0.0       0.447696   0.431691     0.0        1.46283   0.0\n",
       " 0.0       0.204454  0.0        1.62528      0.0        1.36814   0.318914\n",
       " 0.189558  0.0       0.0        1.58516   …  0.0        0.0       0.54103\n",
       " 0.0       1.69819   0.0        1.80811      1.04505    1.22719   0.446802\n",
       " 1.43787   1.59612   0.0150481  0.0          0.0        0.0       0.0830156\n",
       " ⋮                                        ⋱             ⋮         \n",
       " 0.393974  0.865852  0.0        0.247107  …  0.127918   0.663649  0.0\n",
       " 0.0       1.25875   0.51996    0.0          0.0        0.0       0.0\n",
       " 0.0       0.0       0.0        1.06391      0.0        0.0       2.35187\n",
       " 0.0       0.0       0.53268    0.0          0.470567   0.978099  0.0\n",
       " 0.0       0.0       1.66921    0.397357     1.75522    0.0       0.0\n",
       " 0.0       1.43806   0.548526   2.87614   …  0.0        0.0       0.0\n",
       " 1.20162   0.0       0.0        0.189107     0.0101808  0.16511   1.58889\n",
       " 0.0       0.0       0.0        2.26973      0.160704   0.0       0.336089\n",
       " 2.30742   0.742558  1.7235     0.0          0.0        2.75329   0.0\n",
       " 0.145941  0.0       0.0        0.159784     0.0        0.381782  0.0\n",
       " 1.54614   0.0       1.98222    0.0       …  0.0127672  0.0       0.0\n",
       " 1.50771   1.99446   0.0        0.369616     0.610296   0.0       0.0\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.0        0.0       0.0       0.0       …  0.0       0.195237   0.0\n",
       " 0.839638   0.0       0.0       0.0          1.83858   0.0        0.0\n",
       " 2.047      0.909918  0.793394  1.44088      0.0       0.0        0.663191\n",
       " 1.90303    1.16561   0.0       0.777965     0.0       1.06301    0.0\n",
       " 0.991205   1.73093   0.383928  0.0          1.36633   0.0        0.0\n",
       " 0.904476   1.13486   0.0       2.26615   …  0.477775  1.22084    0.0\n",
       " 0.0        0.0       1.47749   0.0          0.437543  0.0        0.00705971\n",
       " 0.0        1.5435    0.0       0.0          0.987576  0.0        0.451523\n",
       " 0.516437   0.0       0.0       0.768275     0.0       1.18538    0.0\n",
       " 0.0        0.0       1.04303   0.0          1.2913    0.0        0.764032\n",
       " 0.0        0.359051  0.0       0.0       …  0.566008  0.0        0.0\n",
       " 0.0        2.14322   0.210289  0.700427     0.177641  0.203626   1.18102\n",
       " 1.02518    0.0       0.0       1.07032      0.14338   1.39491    0.682155\n",
       " ⋮                                        ⋱            ⋮          \n",
       " 0.0        1.21021   0.967256  0.0       …  0.898315  0.0        2.21632\n",
       " 0.0        0.826127  0.0       0.569044     1.27198   0.0474879  2.0229\n",
       " 0.127116   0.0       0.0       0.0          0.0       0.0        0.0\n",
       " 0.0        0.142862  1.28698   0.0          0.0       0.0        0.511087\n",
       " 0.498953   0.0       0.0       0.401689     0.0       0.392218   1.75497\n",
       " 0.0        0.307472  0.20145   0.945266  …  1.32968   0.699021   0.0\n",
       " 0.0        0.0       0.0       0.6035       0.783921  0.698211   0.967655\n",
       " 0.0426933  0.445612  0.0       0.948577     0.0       0.891806   0.0\n",
       " 1.07149    1.13945   0.606313  0.761555     0.690136  1.70604    0.961489\n",
       " 0.138657   0.654497  0.0       0.467226     0.0       1.96436    0.0426919\n",
       " 0.0        0.0       0.0       0.0       …  0.662289  0.0        0.0\n",
       " 0.820063   0.0       0.7642    0.0          0.131091  0.0        0.205758\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 1.1011     0.0        0.593691  0.0211785  …  0.445631  1.34288    0.445501\n",
       " 0.50874    0.0        1.70564   0.0           0.213366  1.95426    0.989622\n",
       " 0.0        0.435039   1.20503   0.0567744     0.830029  0.313429   1.20502\n",
       " 0.0        0.0        1.09509   0.105817      0.54012   0.472052   0.0\n",
       " 0.384554   0.0        0.111745  0.589419      0.361579  1.7958     0.0\n",
       " 0.0        0.0312888  0.0       0.186862   …  0.0       0.0        0.0\n",
       " 1.06686    0.0        0.137002  0.0           0.786733  0.157467   0.0\n",
       " 0.0        0.0        1.34701   0.0           0.302394  0.0        0.0\n",
       " 1.15048    0.0        0.607897  0.963731      0.0       0.814639   0.0\n",
       " 0.0931551  0.0        0.0       0.0           0.550318  1.61334    0.566067\n",
       " 1.88991    0.0        0.0       0.962137   …  0.0       0.028596   0.0\n",
       " 0.0        0.0        0.0       0.0           0.0       0.0356491  0.513437\n",
       " 0.234099   0.0        0.0       0.78124       0.0       0.0394984  0.0\n",
       " ⋮                                          ⋱            ⋮          \n",
       " 0.0        0.507758   0.302187  1.21114    …  0.0       1.19782    0.0\n",
       " 0.0        0.0        0.496445  0.0287454     1.0062    0.280274   0.503464\n",
       " 0.0        1.44914    0.0       0.0           0.0       0.0        1.2132\n",
       " 2.08069    0.365163   0.0       0.0           1.12371   0.0        1.26844\n",
       " 0.859849   0.0        0.170741  0.309781      0.0       0.798262   0.0\n",
       " 0.0        0.895181   0.0       0.0        …  0.0       0.0        0.818458\n",
       " 0.0        1.95544    0.0       0.0           0.0       1.56057    0.0\n",
       " 0.467466   0.0        0.921826  0.0           0.0       0.0        0.0\n",
       " 0.0        1.56688    0.0       0.473062      0.0       0.0        0.943952\n",
       " 0.0        0.225453   2.12136   0.0           0.0       0.696461   0.0\n",
       " 0.0        0.0        0.23556   0.578347   …  0.0       0.0        0.0\n",
       " 0.26121    2.75004    1.1336    0.0           1.62357   0.0        0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time dummybb_a(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BottleneckBlock_c"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a convolutional layer:\n",
    "struct BottleneckBlock_c; w0; w1; w2; w3; p; end\n",
    "(this::BottleneckBlock_c)(x) = relu.(\n",
    "    conv4(this.w3, dropout(\n",
    "            relu.(conv4(this.w2, dropout(\n",
    "                    relu.(conv4(this.w1, dropout(x,this.p),stride=2))\n",
    "                    ,this.p),\n",
    "                    padding=1)\n",
    "                )\n",
    "            ,this.p)) .+\n",
    "    conv4(this.w0, dropout(x,this.p),stride=2)\n",
    ")\n",
    "BottleneckBlock_c(cx::Int,cy::Int,ci::Int;pdrop=0) =\n",
    "    BottleneckBlock_c(\n",
    "        param(1,1,cx,cy), #w0\n",
    "        param(1,1,cx,ci), #w1\n",
    "        param(3,3,ci,ci), #w2\n",
    "        param(1,1,ci,cy), #w3\n",
    "        pdrop\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BottleneckBlock_c(P(KnetArray{Float32,4}(1,1,3,1)), P(KnetArray{Float32,4}(1,1,3,2)), P(KnetArray{Float32,4}(3,3,2,2)), P(KnetArray{Float32,4}(1,1,2,1)), 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummybb_c = BottleneckBlock_c(3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.226677 seconds (582.74 k allocations: 31.023 MiB, 7.60% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256×256×1×1 KnetArray{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.0       0.259841   0.0        1.19015    …  0.337331  0.0        0.996897\n",
       " 1.23436   1.15098    0.149838   0.0           0.888061  0.0        0.248614\n",
       " 1.236     0.158171   0.0        0.395779      0.0       3.04839    0.0\n",
       " 0.722186  1.64074    0.90629    0.0           0.0       1.52061    0.0\n",
       " 1.41872   0.391236   0.0        0.898133      1.37035   0.0        0.793682\n",
       " 0.569994  0.0        1.8065     0.0462089  …  0.0       0.0        0.0\n",
       " 1.15272   0.0        1.22494    1.71573       0.455934  0.0        1.13586\n",
       " 0.0       1.45388    0.719307   1.16118       0.956943  0.797954   0.880557\n",
       " 0.0       0.0        2.05572    0.0           1.44114   0.535114   0.0\n",
       " 1.30601   0.0        0.626656   0.37887       0.9283    2.76353    0.0\n",
       " 0.870601  0.0        0.0        0.741804   …  0.448237  0.0699344  0.0\n",
       " 0.0       0.889106   0.0164227  0.938426      1.15358   0.0196386  1.50882\n",
       " 1.08644   0.0        0.967996   0.2096        1.2358    0.0        0.624091\n",
       " ⋮                                          ⋱                       ⋮\n",
       " 1.04046   0.0        0.0        0.759164      0.450354  0.317027   1.04051\n",
       " 0.0       0.294212   0.226366   1.85937    …  1.82881   0.0        0.0\n",
       " 0.0       0.0646317  0.954597   0.0           0.0       0.0        1.15585\n",
       " 0.0       0.202715   1.45299    0.208304      0.505299  0.801031   0.0\n",
       " 0.0       0.126861   0.0        1.39073       0.0       0.568072   0.142672\n",
       " 0.0       0.0        0.236163   0.402107      0.221322  2.28816    0.0\n",
       " 0.0       0.994971   0.443984   0.619864   …  1.25178   1.89784    0.0\n",
       " 1.05174   0.0344187  0.486791   0.466006      0.0       0.572109   0.0\n",
       " 2.06004   0.0        0.0        0.0           0.0       1.16984    0.818743\n",
       " 0.0       0.0948679  1.9914     0.807874      1.86652   0.451501   1.12853\n",
       " 0.591688  0.60293    0.182362   0.0           1.22399   0.0607252  0.0836201\n",
       " 0.0       0.0        0.0        0.0        …  0.0       0.0        0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time dummybb_c(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Chain\n",
    "    layers\n",
    "    Chain(layers...) = new(layers)\n",
    "end\n",
    "(c::Chain)(x) = (for l in c.layers; x = l(x); end; x)\n",
    "(c::Chain)(x,y) = sse(c(x),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain((BasicStem(P(KnetArray{Float32,4}(7,7,3,64)), P(KnetArray{Float32,4}(1,1,64,1)), Knet.Ops20.relu, 0), BottleneckBlock_b(P(KnetArray{Float32,4}(1,1,64,256)), P(KnetArray{Float32,4}(1,1,64,64)), P(KnetArray{Float32,4}(3,3,64,64)), P(KnetArray{Float32,4}(1,1,64,256)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,256,64)), P(KnetArray{Float32,4}(3,3,64,64)), P(KnetArray{Float32,4}(1,1,64,256)), 0), BottleneckBlock_c(P(KnetArray{Float32,4}(1,1,256,512)), P(KnetArray{Float32,4}(1,1,256,128)), P(KnetArray{Float32,4}(3,3,128,128)), P(KnetArray{Float32,4}(1,1,128,512)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,512,128)), P(KnetArray{Float32,4}(3,3,128,128)), P(KnetArray{Float32,4}(1,1,128,512)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,512,128)), P(KnetArray{Float32,4}(3,3,128,128)), P(KnetArray{Float32,4}(1,1,128,512)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,512,128)), P(KnetArray{Float32,4}(3,3,128,128)), P(KnetArray{Float32,4}(1,1,128,512)), 0), BottleneckBlock_c(P(KnetArray{Float32,4}(1,1,512,1024)), P(KnetArray{Float32,4}(1,1,512,256)), P(KnetArray{Float32,4}(3,3,256,256)), P(KnetArray{Float32,4}(1,1,256,1024)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,1024,256)), P(KnetArray{Float32,4}(3,3,256,256)), P(KnetArray{Float32,4}(1,1,256,1024)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,1024,256)), P(KnetArray{Float32,4}(3,3,256,256)), P(KnetArray{Float32,4}(1,1,256,1024)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,1024,256)), P(KnetArray{Float32,4}(3,3,256,256)), P(KnetArray{Float32,4}(1,1,256,1024)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,1024,256)), P(KnetArray{Float32,4}(3,3,256,256)), P(KnetArray{Float32,4}(1,1,256,1024)), 0), BottleneckBlock_c(P(KnetArray{Float32,4}(1,1,1024,2048)), P(KnetArray{Float32,4}(1,1,1024,512)), P(KnetArray{Float32,4}(3,3,512,512)), P(KnetArray{Float32,4}(1,1,512,2048)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,2048,4096)), P(KnetArray{Float32,4}(3,3,4096,4096)), P(KnetArray{Float32,4}(1,1,4096,2048)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,2048,4096)), P(KnetArray{Float32,4}(3,3,4096,4096)), P(KnetArray{Float32,4}(1,1,4096,2048)), 0)))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone = Chain(\n",
    "    BasicStem(7,7,3,64),\n",
    "    BottleneckBlock_b(64,256),\n",
    "    BottleneckBlock_a(256,64),\n",
    "    BottleneckBlock_c(256,512,128),\n",
    "    BottleneckBlock_a(512,128),\n",
    "    BottleneckBlock_a(512,128),\n",
    "    BottleneckBlock_a(512,128),\n",
    "    BottleneckBlock_c(512,1024,256),\n",
    "    BottleneckBlock_a(1024,256),\n",
    "    BottleneckBlock_a(1024,256),\n",
    "    BottleneckBlock_a(1024,256),\n",
    "    BottleneckBlock_a(1024,256),\n",
    "    BottleneckBlock_c(1024,2048,512),\n",
    "    BottleneckBlock_a(2048,4096),\n",
    "    BottleneckBlock_a(2048,4096),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.289268 seconds (1.55 M allocations: 81.046 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16×16×2048×1 KnetArray{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.0        0.0019023  0.00983799  …  0.0        0.0         0.0142959\n",
       " 0.0258378  0.0254935  0.0192449      0.0193629  0.0196242   0.0149422\n",
       " 0.0315548  0.0436926  0.0198608      0.0373575  0.036246    0.0229732\n",
       " 0.0224715  0.0255725  0.0354985      0.0386999  0.0264843   0.0256632\n",
       " 0.0306949  0.0460532  0.0356504      0.0363406  0.0341441   0.010619\n",
       " 0.0244115  0.0268852  0.0536154   …  0.0322514  0.0244651   0.0088153\n",
       " 0.0301859  0.0213732  0.0421636      0.0601192  0.0400615   0.023701\n",
       " 0.0241582  0.0398711  0.0388851      0.0369853  0.033705    0.0172734\n",
       " 0.0390706  0.02827    0.0362115      0.0415402  0.0313748   0.0115358\n",
       " 0.0271671  0.0215233  0.0356906      0.0541072  0.0299694   0.0181748\n",
       " 0.0233642  0.031591   0.0232809   …  0.046913   0.0423421   0.01961\n",
       " 0.0237943  0.0260807  0.0330564      0.0431888  0.00946233  0.0223585\n",
       " 0.0282296  0.0279735  0.0357545      0.0435145  0.0393461   0.0199641\n",
       " 0.0227538  0.0341361  0.0368278      0.0373717  0.0245624   0.026564\n",
       " 0.0298305  0.0304723  0.0481714      0.0437895  0.0272318   0.0222304\n",
       " 0.022105   0.0388053  0.0413755   …  0.0424758  0.0317433   0.0054846\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.0734966  0.0579585  0.0540711  …  0.0745234  0.0370388  0.086363\n",
       " 0.117696   0.0855414  0.123601      0.131796   0.0866559  0.166586\n",
       " 0.070686   0.181374   0.176173      0.119226   0.118737   0.112189\n",
       " 0.106857   0.0704237  0.133232      0.159057   0.141824   0.155169\n",
       " 0.110856   0.110761   0.156684      0.0976205  0.0831855  0.166878\n",
       " 0.0975056  0.116383   0.158093   …  0.136443   0.150812   0.158927\n",
       " 0.0923096  0.0909081  0.106332      0.15743    0.1578     0.208364\n",
       " 0.115558   0.0796235  0.176123      0.107642   0.135429   0.164623\n",
       " 0.135201   0.100762   0.138126      0.0908436  0.0657839  0.134091\n",
       " 0.0673852  0.144272   0.175439      0.136147   0.131448   0.161348\n",
       " 0.106416   0.126431   0.157761   …  0.129484   0.16933    0.141922\n",
       " 0.145552   0.134356   0.180007      0.157608   0.124419   0.184584\n",
       " 0.0901928  0.0613111  0.116611      0.0973945  0.145747   0.109067\n",
       " 0.11712    0.135549   0.0892759     0.109976   0.117151   0.127453\n",
       " 0.143634   0.0916191  0.0967352     0.122718   0.141311   0.129143\n",
       " 0.115809   0.0555729  0.137234   …  0.0954636  0.146166   0.138746\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 0.0297515  0.0440132  0.050783   …  0.0556337   0.0506682  0.0333451\n",
       " 0.0430297  0.02594    0.0474492     0.0589736   0.0601462  0.0286498\n",
       " 0.03585    0.0679344  0.0649477     0.0544301   0.0610455  0.0314948\n",
       " 0.0482115  0.0361809  0.0688255     0.0535874   0.062727   0.0436909\n",
       " 0.0364705  0.0484467  0.043066      0.0580507   0.0471532  0.0399403\n",
       " 0.0231893  0.0294307  0.0605811  …  0.0630814   0.0620425  0.0255436\n",
       " 0.031847   0.0494075  0.0590087     0.0820897   0.0491587  0.036966\n",
       " 0.0381187  0.0419619  0.051385      0.0618827   0.0635998  0.0461359\n",
       " 0.0464398  0.026358   0.0726892     0.0623633   0.0716206  0.0429965\n",
       " 0.0366863  0.0297643  0.0668095     0.077662    0.056154   0.0259159\n",
       " 0.0444051  0.0281218  0.0590572  …  0.0694607   0.0494412  0.0326445\n",
       " 0.0457351  0.0485279  0.0584585     0.0677855   0.0475527  0.0358375\n",
       " 0.035535   0.0448526  0.0424434     0.0560128   0.0604678  0.0478593\n",
       " 0.0340269  0.0582341  0.0634031     0.059257    0.0416175  0.0299108\n",
       " 0.0225916  0.0414957  0.0555521     0.0613718   0.0403134  0.0354901\n",
       " 0.0811728  0.0134807  0.029934   …  0.00406069  0.0388956  0.00509181\n",
       "\n",
       "...\n",
       "\n",
       "[:, :, 2046, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.00339701\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.000413355\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.00182497\n",
       "\n",
       "[:, :, 2047, 1] =\n",
       " 0.0209851   0.0370396  0.0375187   …  0.0327882  0.0288217  0.0437045\n",
       " 0.00373653  0.0255374  0.0268099      0.0165629  0.0451221  0.0228862\n",
       " 0.00965767  0.0322051  0.0233666      0.01021    0.0354118  0.0123401\n",
       " 0.00202602  0.0329085  0.00652613     0.0433466  0.0502363  0.0168355\n",
       " 0.0         0.0282714  0.0185722      0.0570036  0.0345187  0.019821\n",
       " 0.0         0.0540178  0.0164911   …  0.0274679  0.0388601  0.0209457\n",
       " 0.0127447   0.0404788  0.0367382      0.0294688  0.0141162  0.0204256\n",
       " 0.0105528   0.0301471  0.0210927      0.0235064  0.0144647  0.0207218\n",
       " 0.0         0.0054601  0.0186437      0.0300193  0.0220962  0.0225217\n",
       " 0.00524129  0.0337897  0.0195553      0.0199973  0.0221753  0.0150254\n",
       " 0.0158846   0.0209144  0.00950047  …  0.0318699  0.0249732  0.0210873\n",
       " 0.0         0.0503199  0.0208082      0.0169501  0.027096   0.0220166\n",
       " 0.00526415  0.0282168  0.0352915      0.0265078  0.0184607  0.0276005\n",
       " 0.0         0.035401   0.0233471      0.0438476  0.0264122  0.0174295\n",
       " 0.0228361   0.0258104  0.0284337      0.033866   0.0370145  0.0333509\n",
       " 0.0121548   0.0238482  0.0149878   …  0.0        0.0        0.0\n",
       "\n",
       "[:, :, 2048, 1] =\n",
       " 0.0         0.0  0.0         0.0         …  0.0         0.0  0.0\n",
       " 0.0         0.0  0.0         0.0            0.0         0.0  0.0\n",
       " 0.0         0.0  0.0         0.0            0.0         0.0  0.0\n",
       " 0.0         0.0  0.0         0.0            0.0         0.0  0.0\n",
       " 0.0058532   0.0  0.0         0.00178605     0.00647166  0.0  0.0\n",
       " 0.0         0.0  0.00332702  0.0         …  0.0         0.0  0.0\n",
       " 0.0         0.0  0.0         0.0            0.0         0.0  0.00234794\n",
       " 0.00480303  0.0  0.0         0.0            0.0         0.0  0.00229463\n",
       " 0.0         0.0  0.0         0.0            0.0         0.0  0.0\n",
       " 0.0         0.0  0.0         0.0            0.0         0.0  0.0\n",
       " 0.0         0.0  0.0         0.0165821   …  0.0         0.0  0.0\n",
       " 0.0         0.0  0.0017322   0.0            0.0         0.0  0.0\n",
       " 0.0         0.0  0.0         0.0            0.0         0.0  0.0\n",
       " 0.0         0.0  0.0         0.0            0.00719317  0.0  0.0\n",
       " 0.0         0.0  0.0         0.0            0.0         0.0  0.0\n",
       " 0.0         0.0  0.0         0.0         …  0.0         0.0  0.00276728"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time backbone(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128×128×64×1 KnetArray{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.0352165  0.540592    0.0963047  …  0.144441   0.236264   0.240665\n",
       " 0.2447     0.0         0.637007      0.337211   0.0        0.516928\n",
       " 0.130041   0.567055    0.153623      0.48537    0.437868   0.460014\n",
       " 0.025715   0.242873    0.363507      0.291884   0.197354   0.269797\n",
       " 0.236543   0.279261    0.148285      0.226635   0.432296   0.37948\n",
       " 0.174989   0.119007    0.26594    …  0.382472   0.644718   0.211079\n",
       " 0.323527   0.0         0.24894       0.363139   0.0544726  0.553465\n",
       " 0.161222   0.25437     0.180551      0.514618   0.256482   0.0827562\n",
       " 0.015004   0.384495    0.117426      0.400887   0.104268   0.731624\n",
       " 0.171283   0.355369    0.0           0.0740212  0.167556   0.216154\n",
       " 0.525138   0.525988    0.0132711  …  0.573255   0.393855   0.223849\n",
       " 0.394108   0.214123    0.125566      0.704633   0.228259   0.158252\n",
       " 0.202818   0.00159973  0.570106      0.273616   0.442646   0.329679\n",
       " ⋮                                 ⋱  ⋮                     \n",
       " 0.359636   0.0769008   0.353222      0.098415   0.226542   0.412952\n",
       " 0.066706   0.390566    0.748638      0.659767   0.314841   0.362162\n",
       " 0.101511   0.342232    0.151005      0.526108   0.0321657  0.294451\n",
       " 0.396871   0.242715    0.551095      0.774579   0.354221   0.412477\n",
       " 0.319607   0.219154    0.442469   …  0.347385   0.202574   0.392155\n",
       " 0.192135   0.295409    0.168379      0.124908   0.509644   0.267217\n",
       " 0.15061    0.305155    0.0           0.0        0.48074    0.00237748\n",
       " 0.250278   0.0         0.0120677     0.333951   0.563599   0.459479\n",
       " 0.223204   0.258197    0.501016      0.35854    0.709123   0.260539\n",
       " 0.147217   0.0570465   0.497491   …  0.555978   0.222073   0.804742\n",
       " 0.291663   0.242828    0.626094      0.458514   0.460982   0.589589\n",
       " 0.123697   0.0         0.391752      0.328358   0.110473   0.278555\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.0400205  0.0        0.277263   …  0.324635   0.331238   0.350492\n",
       " 0.0617431  1.00135    0.281436      0.341443   0.342662   0.110199\n",
       " 0.0421617  0.319536   0.0           0.386583   0.0862887  0.343363\n",
       " 0.512207   0.395156   0.175993      0.268453   0.0        0.0159251\n",
       " 0.478165   0.295666   0.0           0.529954   0.43196    0.27246\n",
       " 0.363241   0.657586   0.268783   …  0.415365   0.239529   0.0779969\n",
       " 0.282491   0.2748     0.0           0.199815   0.231853   0.374207\n",
       " 0.476555   0.0689316  0.0991334     0.29501    0.0        0.0456714\n",
       " 0.181306   0.753125   0.606802      0.348963   0.344454   0.0483115\n",
       " 0.274412   0.495315   0.0360098     0.0583528  0.35611    0.42945\n",
       " 0.451097   0.430923   0.558975   …  0.128815   0.0348643  0.265353\n",
       " 0.296309   0.236119   0.0694155     0.163456   0.398108   0.29792\n",
       " 0.552509   0.519881   0.111488      0.0283637  0.145131   0.53649\n",
       " ⋮                                ⋱  ⋮                     \n",
       " 0.231952   0.316343   0.188235      0.354051   0.10108    0.0311844\n",
       " 0.510435   0.07701    0.422741      0.17399    0.0936565  0.248045\n",
       " 0.13685    0.41655    0.414471      0.293987   0.352305   0.407162\n",
       " 0.313575   0.285085   0.391456      0.235614   0.667598   0.270001\n",
       " 0.529659   0.324158   0.11543    …  0.0627592  0.0324406  0.113568\n",
       " 0.0        0.0558145  0.0675658     0.661051   0.232193   0.503093\n",
       " 0.371042   0.547455   0.268243      0.210503   0.0209743  0.1754\n",
       " 0.344656   0.434384   0.302666      0.203453   0.257336   0.289951\n",
       " 0.249712   0.119896   0.436565      0.169929   0.292587   0.540585\n",
       " 0.510659   0.316992   0.415941   …  0.0696122  0.0        0.416619\n",
       " 0.313457   0.737178   0.0301788     0.0623598  0.519292   0.438737\n",
       " 0.0563584  0.610786   0.0900024     0.125218   0.11167    0.383834\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 0.380173   0.27485   0.66586    …  0.210755   0.208424   0.243552\n",
       " 0.542486   0.29309   0.522372      0.0775518  0.3932     0.208378\n",
       " 0.538771   0.246338  0.0898867     0.337752   0.78193    0.319699\n",
       " 0.0        0.0       0.454928      0.245171   0.552178   0.203335\n",
       " 0.308046   0.638927  0.142806      0.494268   0.0        0.482196\n",
       " 0.0        0.294583  0.137596   …  0.166859   0.371381   0.228777\n",
       " 0.249767   0.445418  0.137851      0.192693   0.0        0.679779\n",
       " 0.416583   0.134994  0.120085      0.270867   0.373219   0.432715\n",
       " 0.471581   0.0       0.537424      0.222953   0.241963   0.0138176\n",
       " 0.265718   0.125207  0.333706      0.431433   0.306059   0.125131\n",
       " 0.423347   0.628825  0.117572   …  0.372876   0.263108   0.244478\n",
       " 0.578014   0.297502  0.322419      0.345369   0.370332   0.224117\n",
       " 0.163491   0.606536  0.516167      0.361385   0.440911   0.0\n",
       " ⋮                               ⋱  ⋮                     \n",
       " 0.0878827  0.105276  0.0           0.189865   0.436375   0.174609\n",
       " 0.187056   0.484038  0.353543      0.386018   0.0696794  0.229221\n",
       " 0.405767   0.338729  0.213641      0.411052   0.326465   0.134394\n",
       " 0.0753506  0.180747  0.630882      0.136322   0.114821   0.0482208\n",
       " 0.185321   0.414427  0.336179   …  0.429579   0.558084   0.124426\n",
       " 0.115705   0.377757  0.13573       0.413121   0.411044   0.30287\n",
       " 0.249742   0.642801  0.111264      0.528983   0.308169   0.300182\n",
       " 0.232893   0.594859  0.231209      0.0875905  0.357301   0.231838\n",
       " 0.337443   0.272848  0.487227      0.414824   0.179234   0.200421\n",
       " 0.221502   0.0       0.367437   …  0.453888   0.24806    0.228861\n",
       " 0.236047   0.374375  0.483242      0.298942   0.108593   0.294447\n",
       " 0.152076   0.175202  0.329614      0.269923   0.26682    0.218876\n",
       "\n",
       "...\n",
       "\n",
       "[:, :, 62, 1] =\n",
       " 0.148941   0.401272   0.820758   …  0.311773   0.109156   0.199958\n",
       " 0.137196   0.173554   0.54044       0.0        0.483314   0.1109\n",
       " 0.536385   0.571105   0.371218      0.299224   0.296495   0.349864\n",
       " 0.628428   0.241859   0.655435      0.44936    0.486043   0.361725\n",
       " 0.108148   0.653864   0.506395      0.36492    0.539211   0.148645\n",
       " 0.465525   0.385979   0.242136   …  0.18441    0.0901842  0.346077\n",
       " 0.287749   0.0876914  0.584017      0.0609016  0.24664    0.0836097\n",
       " 0.542327   0.549954   0.844625      0.895237   0.149403   0.402199\n",
       " 0.587594   0.178237   0.406227      0.691397   0.459343   0.201863\n",
       " 0.696227   0.397708   0.734008      0.0406083  0.288644   0.192933\n",
       " 0.596835   0.544444   0.519314   …  0.222196   0.588984   0.0704219\n",
       " 0.260184   0.343004   0.254168      0.256536   0.504478   0.244987\n",
       " 0.0        0.362527   0.182125      0.372585   0.264774   0.764945\n",
       " ⋮                                ⋱  ⋮                     \n",
       " 0.0        0.695934   0.518587      0.523011   0.366457   0.420229\n",
       " 0.789121   0.0        0.508568      0.168733   0.27367    0.026171\n",
       " 0.818145   0.0        0.0932459     0.522512   0.237313   0.256994\n",
       " 0.318818   0.203083   0.300671      0.141186   0.417868   0.11682\n",
       " 0.160116   0.854894   0.387312   …  0.416633   0.297774   0.0690364\n",
       " 0.034149   0.179849   0.473652      0.265544   0.269857   0.0872626\n",
       " 0.270229   0.566412   0.405456      0.434611   0.273291   0.077269\n",
       " 0.235665   0.300275   0.478298      0.413749   0.353544   0.410549\n",
       " 0.345373   0.0        0.267873      0.0773961  0.422414   0.367334\n",
       " 0.184174   0.467293   0.598598   …  0.411382   0.0        0.604486\n",
       " 0.284714   0.440433   0.702536      0.337905   0.0        0.158919\n",
       " 0.0280357  0.82788    0.0741625     0.519313   0.43731    0.403878\n",
       "\n",
       "[:, :, 63, 1] =\n",
       " 0.157303    0.34908   0.107346    …  0.0886541  0.364106   0.129082\n",
       " 0.0875393   0.303404  0.183148       0.130856   0.0        0.129835\n",
       " 0.336585    0.391034  0.614737       0.322748   0.385668   0.50101\n",
       " 0.263923    0.223112  0.676458       0.201447   0.439388   0.216099\n",
       " 0.00273786  0.442064  0.11334        0.353386   0.411542   0.508303\n",
       " 0.409863    0.191238  0.260406    …  0.621288   0.141262   0.206016\n",
       " 0.0260938   0.436919  0.146361       0.718366   0.173878   0.174303\n",
       " 0.113425    0.377243  0.158322       0.207267   0.0        0.328858\n",
       " 0.151237    0.469469  0.434262       0.357456   0.214276   0.487618\n",
       " 0.209166    0.439593  0.240892       0.0478709  0.0823     0.280965\n",
       " 0.12688     0.314429  0.0         …  0.361973   0.126403   0.265966\n",
       " 0.346677    0.226151  0.307046       0.141286   0.317959   0.182644\n",
       " 0.141788    0.135368  0.186343       0.369623   0.199549   0.150663\n",
       " ⋮                                 ⋱  ⋮                     \n",
       " 0.191493    0.470604  0.552036       0.197622   0.494993   0.0299587\n",
       " 0.257251    0.184382  0.314014       0.197326   0.0276884  0.109011\n",
       " 0.0         0.0       0.381033       0.542746   0.0913832  0.245227\n",
       " 0.121508    0.482932  0.0            0.334893   0.378859   0.317777\n",
       " 0.267699    0.201263  0.574702    …  0.564217   0.70193    0.532361\n",
       " 0.805294    0.227295  0.31919        0.514184   0.317251   0.482663\n",
       " 0.147805    0.446917  0.556155       0.452551   0.694792   0.459604\n",
       " 0.0650315   0.179919  0.192784       0.0        0.364002   0.290789\n",
       " 0.0553067   0.508064  0.0516833      0.398819   0.264324   0.201817\n",
       " 0.26069     0.207081  0.311215    …  0.0        0.328805   0.202219\n",
       " 0.330614    0.354679  0.270785       0.209208   0.255477   0.00389605\n",
       " 0.240552    0.124289  0.00962585     0.0        0.360978   0.321564\n",
       "\n",
       "[:, :, 64, 1] =\n",
       " 0.157068   0.194596   0.123316   …  0.180339   0.0853057   0.108276\n",
       " 0.558773   0.167199   0.257685      0.343989   0.538751    0.647518\n",
       " 0.374679   0.258744   0.334322      0.262651   0.387369    0.25749\n",
       " 0.247935   0.545847   0.32398       0.715893   0.415285    0.0454818\n",
       " 0.527755   0.113239   0.671085      0.149779   0.228506    0.295374\n",
       " 0.478956   0.142454   0.0815606  …  0.345905   0.204434    0.663793\n",
       " 0.125385   0.163653   0.29875       0.30265    0.259607    0.102979\n",
       " 0.347623   0.42574    0.14806       0.627563   0.0         0.513413\n",
       " 0.0944     0.807197   0.402534      0.676505   0.219464    0.68334\n",
       " 0.298631   0.371057   0.158729      0.335761   0.443447    0.586026\n",
       " 0.28053    0.0818351  0.411672   …  0.516979   0.446697    0.438865\n",
       " 0.503588   0.255122   0.122421      0.552899   0.606307    0.079556\n",
       " 0.372797   0.198839   0.470804      0.45494    0.169747    0.367689\n",
       " ⋮                                ⋱  ⋮                      \n",
       " 0.235844   0.315568   0.348644      0.197135   0.46981     0.167091\n",
       " 0.256412   0.241559   0.741779      0.0375133  0.219606    0.270362\n",
       " 0.267937   0.0118537  0.193801      0.427009   0.0         0.115217\n",
       " 0.0186788  0.574214   0.425252      0.119813   0.0         0.328668\n",
       " 0.174259   0.413089   0.621902   …  0.208661   0.471251    0.723472\n",
       " 0.108466   0.173214   0.200652      0.337228   0.249492    0.284044\n",
       " 0.319181   0.206422   0.482716      0.241563   0.474185    0.313595\n",
       " 0.157735   0.221909   0.376515      0.348049   0.504911    0.0926616\n",
       " 0.380754   0.21055    0.391482      0.3957     0.00592559  0.416552\n",
       " 0.317215   0.0813933  0.379795   …  0.447017   0.559157    0.357498\n",
       " 0.458589   0.267035   0.288053      0.350684   0.581241    0.265975\n",
       " 0.0297856  0.385812   0.277365      0.276446   0.342733    0.238175"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BasicStem(7,7,3,64)(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Pyramid\n",
    "    stem\n",
    "    layers\n",
    "    Pyramid(stem, layers...) = new(stem,layers)\n",
    "end\n",
    "function (p::Pyramid)(x)\n",
    "    # Climbing up the pyramid\n",
    "    r = p.stem(x);\n",
    "    featureMaps = ();\n",
    "    for l in p.layers;\n",
    "        r = l(r);\n",
    "        featureMaps = (featureMaps...,r);\n",
    "    end\n",
    "    featureMaps;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pyramid(BasicStem(P(KnetArray{Float32,4}(7,7,3,64)), P(KnetArray{Float32,4}(1,1,64,1)), Knet.Ops20.relu, 0), (Chain((BottleneckBlock_b(P(KnetArray{Float32,4}(1,1,64,256)), P(KnetArray{Float32,4}(1,1,64,64)), P(KnetArray{Float32,4}(3,3,64,64)), P(KnetArray{Float32,4}(1,1,64,256)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,256,64)), P(KnetArray{Float32,4}(3,3,64,64)), P(KnetArray{Float32,4}(1,1,64,256)), 0))), Chain((BottleneckBlock_c(P(KnetArray{Float32,4}(1,1,256,512)), P(KnetArray{Float32,4}(1,1,256,128)), P(KnetArray{Float32,4}(3,3,128,128)), P(KnetArray{Float32,4}(1,1,128,512)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,512,128)), P(KnetArray{Float32,4}(3,3,128,128)), P(KnetArray{Float32,4}(1,1,128,512)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,512,128)), P(KnetArray{Float32,4}(3,3,128,128)), P(KnetArray{Float32,4}(1,1,128,512)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,512,128)), P(KnetArray{Float32,4}(3,3,128,128)), P(KnetArray{Float32,4}(1,1,128,512)), 0))), Chain((BottleneckBlock_c(P(KnetArray{Float32,4}(1,1,512,1024)), P(KnetArray{Float32,4}(1,1,512,256)), P(KnetArray{Float32,4}(3,3,256,256)), P(KnetArray{Float32,4}(1,1,256,1024)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,1024,256)), P(KnetArray{Float32,4}(3,3,256,256)), P(KnetArray{Float32,4}(1,1,256,1024)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,1024,256)), P(KnetArray{Float32,4}(3,3,256,256)), P(KnetArray{Float32,4}(1,1,256,1024)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,1024,256)), P(KnetArray{Float32,4}(3,3,256,256)), P(KnetArray{Float32,4}(1,1,256,1024)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,1024,256)), P(KnetArray{Float32,4}(3,3,256,256)), P(KnetArray{Float32,4}(1,1,256,1024)), 0))), Chain((BottleneckBlock_c(P(KnetArray{Float32,4}(1,1,1024,2048)), P(KnetArray{Float32,4}(1,1,1024,512)), P(KnetArray{Float32,4}(3,3,512,512)), P(KnetArray{Float32,4}(1,1,512,2048)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,2048,4096)), P(KnetArray{Float32,4}(3,3,4096,4096)), P(KnetArray{Float32,4}(1,1,4096,2048)), 0), BottleneckBlock_a(P(KnetArray{Float32,4}(1,1,2048,4096)), P(KnetArray{Float32,4}(3,3,4096,4096)), P(KnetArray{Float32,4}(1,1,4096,2048)), 0))), Chain((var\"#6#7\"(),))))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone = Pyramid(\n",
    "    BasicStem(7,7,3,64),\n",
    "    Chain(\n",
    "        BottleneckBlock_b(64,256),\n",
    "        BottleneckBlock_a(256,64)\n",
    "        ),\n",
    "    Chain(\n",
    "        BottleneckBlock_c(256,512,128),\n",
    "        BottleneckBlock_a(512,128),\n",
    "        BottleneckBlock_a(512,128),\n",
    "        BottleneckBlock_a(512,128),\n",
    "        ),\n",
    "    Chain(\n",
    "        BottleneckBlock_c(512,1024,256),\n",
    "        BottleneckBlock_a(1024,256),\n",
    "        BottleneckBlock_a(1024,256),\n",
    "        BottleneckBlock_a(1024,256),\n",
    "        BottleneckBlock_a(1024,256),\n",
    "        ),\n",
    "    Chain(\n",
    "        BottleneckBlock_c(1024,2048,512),\n",
    "        BottleneckBlock_a(2048,4096),\n",
    "        BottleneckBlock_a(2048,4096),\n",
    "        ),\n",
    "    Chain(\n",
    "        x -> pool(x)\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.028324 seconds (54.44 k allocations: 2.939 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(K32(128,128,256,1)[0.3458485⋯], K32(64,64,512,1)[0.012571201⋯], K32(32,32,1024,1)[0.09636523⋯], K32(16,16,2048,1)[0.065328695⋯], K32(8,8,2048,1)[0.12434062⋯])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time pyramid_o = backbone(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct FPN\n",
    "    pyramid\n",
    "    lateral_layers\n",
    "    output_layers\n",
    "    FPN(pyramid,lateral_layers,output_layers) =\n",
    "        new(pyramid,lateral_layers,output_layers)\n",
    "end\n",
    "function (fpn::FPN)(x)\n",
    "    # Climbing up the pyramid\n",
    "    y = fpn.pyramid(x);\n",
    "    L = ();\n",
    "    # Reduce #channels\n",
    "    for i in 1:length(fpn.lateral_layers)\n",
    "        L = (L...,fpn.lateral_layers[i](y[i]))\n",
    "    end\n",
    "    # upsample and add\n",
    "    \n",
    "    # output\n",
    "    O = ();\n",
    "    for i in 1:length(fpn.output_layers)\n",
    "        O = (O...,fpn.output_layers[i](L[i]))\n",
    "    end\n",
    "    (O...,L[end])\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "onlyConv"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "struct onlyConv; w; f; p; pad; end\n",
    "(c::onlyConv)(x) = c.f.(conv4(c.w, dropout(x,c.p),padding=c.pad))\n",
    "onlyConv(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0,padding=0) =\n",
    "onlyConv(param(w1,w2,cx,cy), f, pdrop,padding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "myFPN = FPN(\n",
    "    backbone,\n",
    "    [\n",
    "        onlyConv(1,1,256,256),\n",
    "        onlyConv(1,1,512,256),\n",
    "        onlyConv(1,1,1024,256),\n",
    "        onlyConv(1,1,2048,256),\n",
    "        onlyConv(1,1,2048,256)\n",
    "    ],\n",
    "    [\n",
    "        onlyConv(3,3,256,256,padding=1),\n",
    "        onlyConv(3,3,256,256,padding=1),\n",
    "        onlyConv(3,3,256,256,padding=1),\n",
    "        onlyConv(3,3,256,256,padding=1)\n",
    "    ]\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(K32(128,128,256,1)[0.0⋯], K32(64,64,256,1)[0.0⋯], K32(32,32,256,1)[0.036092877⋯], K32(16,16,256,1)[0.03522419⋯], K32(8,8,256,1)[0.11121067⋯])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpn_dummy = myFPN(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@benchmark myFPN(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct RPN_head\n",
    "    conv_plain\n",
    "    objectness_logit_conv\n",
    "    anchor_deltas_conv\n",
    "    RPN_head(conv_plain,objectness_logit_conv,anchor_deltas_conv) =\n",
    "        new(conv_plain,objectness_logit_conv,anchor_deltas_conv)\n",
    "end\n",
    "function (rpnh::RPN_head)(x)\n",
    "    objectness_logit = [];\n",
    "    anchor_deltas = [];\n",
    "    # for each head in bundle (P2 to P6)\n",
    "    for h in x\n",
    "        temp = rpnh.conv_plain(h)\n",
    "        push!(objectness_logit, rpnh.objectness_logit_conv(temp))\n",
    "        push!(anchor_deltas, rpnh.anchor_deltas_conv(temp))\n",
    "    end\n",
    "    (objectness_logit,anchor_deltas)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RPN_head(onlyConv(P(KnetArray{Float32,4}(3,3,256,256)), Knet.Ops20.relu, 0, 1), onlyConv(P(KnetArray{Float32,4}(1,1,256,3)), Knet.Ops20.sigm, 0, 0), onlyConv(P(KnetArray{Float32,4}(1,1,256,12)), Knet.Ops20.relu, 0, 0))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRPN_head = RPN_head(\n",
    "    onlyConv(3,3,256,256,padding=1),\n",
    "    onlyConv(1,1,256,3,sigm),\n",
    "    onlyConv(1,1,256,3*4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Any[K32(128,128,3,1)[0.50727785⋯], K32(64,64,3,1)[0.49473512⋯], K32(32,32,3,1)[0.5069591⋯], K32(16,16,3,1)[0.4962831⋯], K32(8,8,3,1)[0.50000024⋯]], Any[K32(128,128,12,1)[0.09653285⋯], K32(64,64,12,1)[0.053986758⋯], K32(32,32,12,1)[0.075714104⋯], K32(16,16,12,1)[0.03471388⋯], K32(8,8,12,1)[0.07259219⋯]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_objectness_logits, dummy_anchor_deltas = myRPN_head(fpn_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  215.83 KiB\n",
       "  allocs estimate:  5354\n",
       "  --------------\n",
       "  minimum time:     3.971 ms (0.00% GC)\n",
       "  median time:      106.992 ms (0.00% GC)\n",
       "  mean time:        94.625 ms (0.29% GC)\n",
       "  maximum time:     113.830 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          53\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark myRPN_head(myFPN(dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Any,1}:\n",
       " K32(128,128,3,1)[0.50727785⋯]\n",
       " K32(64,64,3,1)[0.49473512⋯]\n",
       " K32(32,32,3,1)[0.5069591⋯]\n",
       " K32(16,16,3,1)[0.4962831⋯]\n",
       " K32(8,8,3,1)[0.50000024⋯]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_objectness_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Any,1}:\n",
       " K32(128,128,12,1)[0.09653285⋯]\n",
       " K32(64,64,12,1)[0.053986758⋯]\n",
       " K32(32,32,12,1)[0.075714104⋯]\n",
       " K32(16,16,12,1)[0.03471388⋯]\n",
       " K32(8,8,12,1)[0.07259219⋯]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_anchor_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_cell_anchors (generic function with 3 methods)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://github.com/facebookresearch/detectron2/blob/5e2a1ecccd228227c5a605c0a98d58e1b2db3640/detectron2/modeling/anchor_generator.py#L140-L177\n",
    "function generate_cell_anchors(\n",
    "        sizes=(32,64,128,256,512),\n",
    "        aspect_ratios=(0.5,1,2)\n",
    "    )\n",
    "    anchors = []\n",
    "    for size in sizes\n",
    "        anchor = []\n",
    "        area = size ^ 2.0\n",
    "        for aspect_ratio in aspect_ratios\n",
    "            # s * s = w * h\n",
    "            # a = h / w\n",
    "            # ... some algebra ...\n",
    "            # w = sqrt(s * s / a)\n",
    "            # h = a * w\n",
    "            w = sqrt(area / aspect_ratio)\n",
    "            h = aspect_ratio * w\n",
    "            x0, y0, x1, y1 = -w / 2.0, -h / 2.0, w / 2.0, h / 2.0\n",
    "            append!(anchor,[[x0, y0, x1, y1]])\n",
    "        end\n",
    "        append!(anchors,[anchor])\n",
    "    end\n",
    "    anchors\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Any,1}:\n",
       " Any[[-22.627416997969522, -11.313708498984761, 22.627416997969522, 11.313708498984761], [-16.0, -16.0, 16.0, 16.0], [-11.313708498984761, -22.627416997969522, 11.313708498984761, 22.627416997969522]]\n",
       " Any[[-45.254833995939045, -22.627416997969522, 45.254833995939045, 22.627416997969522], [-32.0, -32.0, 32.0, 32.0], [-22.627416997969522, -45.254833995939045, 22.627416997969522, 45.254833995939045]]\n",
       " Any[[-90.50966799187809, -45.254833995939045, 90.50966799187809, 45.254833995939045], [-64.0, -64.0, 64.0, 64.0], [-45.254833995939045, -90.50966799187809, 45.254833995939045, 90.50966799187809]]\n",
       " Any[[-181.01933598375618, -90.50966799187809, 181.01933598375618, 90.50966799187809], [-128.0, -128.0, 128.0, 128.0], [-90.50966799187809, -181.01933598375618, 90.50966799187809, 181.01933598375618]]\n",
       " Any[[-362.03867196751236, -181.01933598375618, 362.03867196751236, 181.01933598375618], [-256.0, -256.0, 256.0, 256.0], [-181.01933598375618, -362.03867196751236, 181.01933598375618, 362.03867196751236]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_anchors = generate_cell_anchors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bb_intersection_over_union (generic function with 1 method)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function bb_intersection_over_union(boxA, boxB)\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[1], boxB[1])\n",
    "    yA = max(boxA[2], boxB[2])\n",
    "    xB = min(boxA[3], boxB[3])\n",
    "    yB = min(boxA[4], boxB[4])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    print(interArea);print(\"\\n\");\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[3] - boxA[1]) * (boxA[4] - boxA[2])\n",
    "    boxBArea = (boxB[3] - boxB[1]) * (boxB[4] - boxB[2])\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / (boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_intersection_over_union(\n",
    "    [0,0,2,1],\n",
    "    [0,0,1,2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element KnetArray{Int64,1}:\n",
       "  4\n",
       "  8\n",
       " 16\n",
       " 32\n",
       " 64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strides = KnetArray([4,8,16,32,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"65472-element Array{Any,1}\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors = []\n",
    "for anchor in 1:length(dummy_anchor_deltas)\n",
    "    a = []\n",
    "    for i = 1:size(dummy_anchor_deltas[anchor],1)\n",
    "        for j = 1:size(dummy_anchor_deltas[anchor],1)\n",
    "            b = []\n",
    "            for c in cell_anchors[anchor]\n",
    "                append!(b,[[strides[anchor]*i,strides[anchor]*j,0,0]+c])\n",
    "            end\n",
    "            append!(a,b) \n",
    "        end\n",
    "    end\n",
    "    append!(anchors,a) \n",
    "end\n",
    "summary(anchors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " -18.627416997969522\n",
       "  -7.313708498984761\n",
       "  22.627416997969522\n",
       "  11.313708498984761"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
